import json

# Security Core Team - ML Threat Detection & Analysis
nb = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”’ Security Analysis Report - ML-Based Threat Detection\n",
                "\n",
                "**Classification**: INTERNAL USE ONLY  \n",
                "**Prepared for**: Security Core Team  \n",
                "**Analysis Type**: Machine Learning Threat Detection & Risk Assessment\n",
                "\n",
                "---\n",
                "\n",
                "## Executive Summary\n",
                "\n",
                "This notebook provides:\n",
                "1. **Automated threat detection** using ML algorithms\n",
                "2. **Risk scoring** for identified threats\n",
                "3. **Actionable intelligence** for incident response\n",
                "4. **Threat actor profiling** and attribution\n",
                "5. **Security recommendations** prioritized by impact\n",
                "\n",
                "### Key Metrics:\n",
                "- Total requests analyzed\n",
                "- Threats detected (by severity)\n",
                "- Top threat actors\n",
                "- Attack vectors identified\n",
                "- Recommended actions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Security Analysis Environment Setup\n",
                "import sys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime, timedelta\n",
                "from sklearn.ensemble import IsolationForest\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import warnings\n",
                "\n",
                "sys.path.append('..')\n",
                "from log_threat_detection.dataset import LogDataset\n",
                "from log_threat_detection.models import ThreatDetector, AnomalyDetector\n",
                "from log_threat_detection.config import *\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "\n",
                "# Analysis timestamp\n",
                "analysis_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
                "print(f'ðŸ”’ Security Analysis Started: {analysis_time}')\n",
                "print('ðŸ“Š Loading threat intelligence modules...')"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Collection & Initial Assessment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Load and preprocess logs\n",
                "dataset = LogDataset()\n",
                "access_df, error_df = dataset.load_all()\n",
                "access_df = dataset.preprocess_access_log(access_df)\n",
                "error_df = dataset.preprocess_error_log(error_df)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ“‹ DATA COLLECTION SUMMARY')\n",
                "print('='*80)\n",
                "print(f'Access Log Entries: {len(access_df):,}')\n",
                "print(f'Error Log Entries: {len(error_df):,}')\n",
                "print(f'Date Range: {access_df[\"timestamp\"].min()} to {access_df[\"timestamp\"].max()}')\n",
                "print(f'Unique Source IPs: {access_df[\"ip\"].nunique():,}')\n",
                "print(f'Analysis Period: {(access_df[\"timestamp\"].max() - access_df[\"timestamp\"].min()).days} days')\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ML-Based Threat Detection\n",
                "\n",
                "### Methodology:\n",
                "- **Isolation Forest Algorithm**: Detects anomalous patterns\n",
                "- **Feature Engineering**: Request volume, error rate, behavior patterns\n",
                "- **Contamination Rate**: 5% (conservative estimate)\n",
                "- **Confidence Threshold**: Z-score > 2 for statistical validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Initialize threat detectors\n",
                "threat_detector = ThreatDetector()\n",
                "anomaly_detector = AnomalyDetector()\n",
                "\n",
                "# Run comprehensive threat analysis\n",
                "print('ðŸ” Running ML-based threat detection...')\n",
                "access_df = threat_detector.analyze_threats(access_df)\n",
                "threat_summary = threat_detector.get_threat_summary(access_df)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸš¨ THREAT DETECTION RESULTS')\n",
                "print('='*80)\n",
                "print(f'Total Requests Analyzed: {threat_summary[\"total_requests\"]:,}')\n",
                "print(f'Threats Detected: {threat_summary[\"total_threats\"]:,} ({threat_summary[\"threat_percentage\"]:.2f}%)')\n",
                "print('\\nBreakdown by Attack Vector:')\n",
                "print(f'  â€¢ SQL Injection Attempts: {threat_summary[\"sql_injection_attempts\"]:,}')\n",
                "print(f'  â€¢ XSS Attacks: {threat_summary[\"xss_attempts\"]:,}')\n",
                "print(f'  â€¢ Path Traversal: {threat_summary[\"path_traversal_attempts\"]:,}')\n",
                "print(f'  â€¢ Suspicious Responses: {threat_summary[\"suspicious_status_codes\"]:,}')\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Threat Severity Classification\n",
                "\n",
                "**Severity Levels:**\n",
                "- ðŸ”´ **CRITICAL** (Score â‰¥15): Immediate action required - Active exploitation attempts\n",
                "- ðŸŸ  **HIGH** (Score â‰¥10): Urgent - Multiple attack vectors or persistent attempts\n",
                "- ðŸŸ¡ **MEDIUM** (Score â‰¥5): Monitor - Single attack vector or reconnaissance\n",
                "- ðŸŸ¢ **LOW** (Score >0): Log - Suspicious but low risk\n",
                "- âšª **NONE** (Score 0): Clean traffic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Classify threats by severity\n",
                "def classify_threat_severity(row):\n",
                "    severity_score = 0\n",
                "    threat_type = []\n",
                "    \n",
                "    if row['sql_injection']:\n",
                "        severity_score += 10\n",
                "        threat_type.append('SQL_INJECTION')\n",
                "    if row['xss_attack']:\n",
                "        severity_score += 8\n",
                "        threat_type.append('XSS')\n",
                "    if row['path_traversal']:\n",
                "        severity_score += 9\n",
                "        threat_type.append('PATH_TRAVERSAL')\n",
                "    if row['suspicious_status']:\n",
                "        severity_score += 5\n",
                "        threat_type.append('SUSPICIOUS_STATUS')\n",
                "    \n",
                "    if severity_score >= 15:\n",
                "        severity = 'CRITICAL'\n",
                "    elif severity_score >= 10:\n",
                "        severity = 'HIGH'\n",
                "    elif severity_score >= 5:\n",
                "        severity = 'MEDIUM'\n",
                "    elif severity_score > 0:\n",
                "        severity = 'LOW'\n",
                "    else:\n",
                "        severity = 'NONE'\n",
                "    \n",
                "    return pd.Series({\n",
                "        'threat_severity': severity,\n",
                "        'threat_score': severity_score,\n",
                "        'threat_types': ','.join(threat_type) if threat_type else 'NONE'\n",
                "    })\n",
                "\n",
                "access_df[['threat_severity', 'threat_score', 'threat_types']] = access_df.apply(classify_threat_severity, axis=1)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ“Š THREAT SEVERITY DISTRIBUTION')\n",
                "print('='*80)\n",
                "severity_counts = access_df['threat_severity'].value_counts()\n",
                "for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'NONE']:\n",
                "    if severity in severity_counts.index:\n",
                "        count = severity_counts[severity]\n",
                "        pct = (count / len(access_df)) * 100\n",
                "        emoji = {'CRITICAL': 'ðŸ”´', 'HIGH': 'ðŸŸ ', 'MEDIUM': 'ðŸŸ¡', 'LOW': 'ðŸŸ¢', 'NONE': 'âšª'}[severity]\n",
                "        print(f'{emoji} {severity:8s}: {count:8,} ({pct:5.2f}%)')\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ML Anomaly Detection - Behavioral Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Build IP behavior profiles for ML analysis\n",
                "print('ðŸ¤– Building IP behavior profiles for ML analysis...')\n",
                "\n",
                "ip_features = access_df.groupby('ip').agg({\n",
                "    'timestamp': 'count',\n",
                "    'status': lambda x: (x >= 400).sum(),\n",
                "    'bytes': 'sum',\n",
                "    'url': 'nunique',\n",
                "    'method': lambda x: (x == 'POST').sum()\n",
                "}).rename(columns={\n",
                "    'timestamp': 'total_requests',\n",
                "    'status': 'error_count',\n",
                "    'bytes': 'total_bytes',\n",
                "    'url': 'unique_urls',\n",
                "    'method': 'post_requests'\n",
                "})\n",
                "\n",
                "# Calculate behavior metrics\n",
                "ip_features['error_rate'] = ip_features['error_count'] / ip_features['total_requests']\n",
                "ip_features['post_rate'] = ip_features['post_requests'] / ip_features['total_requests']\n",
                "ip_features['avg_bytes_per_request'] = ip_features['total_bytes'] / ip_features['total_requests']\n",
                "ip_features['url_diversity'] = ip_features['unique_urls'] / ip_features['total_requests']\n",
                "\n",
                "# Apply Isolation Forest ML model\n",
                "features_for_ml = ip_features[['total_requests', 'error_rate', 'unique_urls', 'post_rate', 'avg_bytes_per_request']].fillna(0)\n",
                "scaler = StandardScaler()\n",
                "features_scaled = scaler.fit_transform(features_for_ml)\n",
                "\n",
                "iso_forest = IsolationForest(contamination=0.05, random_state=42, n_estimators=100)\n",
                "ip_features['ml_anomaly_score'] = iso_forest.fit_predict(features_scaled)\n",
                "ip_features['ml_anomaly'] = ip_features['ml_anomaly_score'] == -1\n",
                "ip_features['ml_confidence_score'] = iso_forest.score_samples(features_scaled)\n",
                "\n",
                "ml_anomalies = ip_features[ip_features['ml_anomaly']].sort_values('total_requests', ascending=False)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ¤– MACHINE LEARNING ANOMALY DETECTION RESULTS')\n",
                "print('='*80)\n",
                "print(f'Total IPs Analyzed: {len(ip_features):,}')\n",
                "print(f'ML-Detected Anomalies: {len(ml_anomalies):,}')\n",
                "print(f'Detection Rate: {(len(ml_anomalies)/len(ip_features)*100):.2f}%')\n",
                "print(f'Algorithm: Isolation Forest (100 estimators, 5% contamination)')\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Threat Actor Profiling & Attribution\n",
                "\n",
                "**Intelligence gathered on threat actors:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Profile threat actors\n",
                "threat_actors = access_df[access_df['threat_detected']].groupby('ip').agg({\n",
                "    'threat_detected': 'count',\n",
                "    'sql_injection': 'sum',\n",
                "    'xss_attack': 'sum',\n",
                "    'path_traversal': 'sum',\n",
                "    'threat_score': 'sum',\n",
                "    'threat_severity': lambda x: (x.isin(['CRITICAL', 'HIGH'])).sum(),\n",
                "    'timestamp': ['min', 'max']\n",
                "}).round(2)\n",
                "\n",
                "threat_actors.columns = ['total_attacks', 'sql_injection', 'xss_attack', 'path_traversal', \n",
                "                         'cumulative_threat_score', 'high_severity_count', 'first_seen', 'last_seen']\n",
                "\n",
                "# Calculate attack duration and frequency\n",
                "threat_actors['attack_duration_hours'] = (threat_actors['last_seen'] - threat_actors['first_seen']).dt.total_seconds() / 3600\n",
                "threat_actors['attacks_per_hour'] = threat_actors['total_attacks'] / threat_actors['attack_duration_hours'].replace(0, 1)\n",
                "\n",
                "# Merge with ML anomaly data\n",
                "threat_actors = threat_actors.join(ml_anomalies[['ml_anomaly', 'error_rate', 'ml_confidence_score']], how='left')\n",
                "threat_actors = threat_actors.sort_values('cumulative_threat_score', ascending=False)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ‘¤ TOP 20 THREAT ACTORS - INTELLIGENCE PROFILE')\n",
                "print('='*80)\n",
                "print(threat_actors.head(20).to_string())\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Risk Assessment & Prioritization Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Create risk assessment matrix\n",
                "risk_matrix = []\n",
                "\n",
                "for ip, data in threat_actors.head(30).iterrows():\n",
                "    # Calculate risk factors\n",
                "    attack_diversity = sum([data['sql_injection'] > 0, data['xss_attack'] > 0, data['path_traversal'] > 0])\n",
                "    persistence_score = data['attack_duration_hours'] * data['attacks_per_hour']\n",
                "    ml_confirmed = 'YES' if data['ml_anomaly'] else 'NO'\n",
                "    \n",
                "    # Determine risk level\n",
                "    if data['cumulative_threat_score'] >= 100 and data['high_severity_count'] >= 5:\n",
                "        risk_level = 'CRITICAL'\n",
                "        action = 'BLOCK IMMEDIATELY'\n",
                "    elif data['cumulative_threat_score'] >= 50 and data['high_severity_count'] >= 2:\n",
                "        risk_level = 'HIGH'\n",
                "        action = 'AGGRESSIVE RATE LIMIT'\n",
                "    elif data['cumulative_threat_score'] >= 20:\n",
                "        risk_level = 'MEDIUM'\n",
                "        action = 'MONITOR & LOG'\n",
                "    else:\n",
                "        risk_level = 'LOW'\n",
                "        action = 'PASSIVE MONITORING'\n",
                "    \n",
                "    risk_matrix.append({\n",
                "        'IP_Address': ip,\n",
                "        'Risk_Level': risk_level,\n",
                "        'Threat_Score': int(data['cumulative_threat_score']),\n",
                "        'Total_Attacks': int(data['total_attacks']),\n",
                "        'High_Severity': int(data['high_severity_count']),\n",
                "        'Attack_Vectors': attack_diversity,\n",
                "        'ML_Confirmed': ml_confirmed,\n",
                "        'Error_Rate': f\"{data['error_rate']*100:.1f}%\" if pd.notna(data['error_rate']) else 'N/A',\n",
                "        'Recommended_Action': action,\n",
                "        'First_Seen': data['first_seen'],\n",
                "        'Last_Seen': data['last_seen']\n",
                "    })\n",
                "\n",
                "risk_df = pd.DataFrame(risk_matrix)\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('âš ï¸  RISK ASSESSMENT MATRIX - TOP 30 THREATS')\n",
                "print('='*80)\n",
                "print(risk_df.to_string(index=False))\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ“Š RISK DISTRIBUTION')\n",
                "print('='*80)\n",
                "print(risk_df['Risk_Level'].value_counts())\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Incident Response Recommendations\n",
                "\n",
                "**Prioritized action items for security team:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Generate incident response playbook\n",
                "print('\\n' + '='*80)\n",
                "print('ðŸ“‹ INCIDENT RESPONSE PLAYBOOK')\n",
                "print('='*80)\n",
                "\n",
                "critical_ips = risk_df[risk_df['Risk_Level'] == 'CRITICAL']['IP_Address'].tolist()\n",
                "high_ips = risk_df[risk_df['Risk_Level'] == 'HIGH']['IP_Address'].tolist()\n",
                "\n",
                "print('\\nðŸ”´ IMMEDIATE ACTIONS (Next 1 hour):')\n",
                "if critical_ips:\n",
                "    print(f'   1. BLOCK {len(critical_ips)} CRITICAL threat IPs in firewall')\n",
                "    print(f'      IPs: {\", \".join(critical_ips[:5])}{\", ...\" if len(critical_ips) > 5 else \"\"}')\n",
                "    print(f'   2. Enable aggressive logging for these IPs')\n",
                "    print(f'   3. Alert SOC team for forensic analysis')\n",
                "else:\n",
                "    print('   âœ“ No critical threats requiring immediate blocking')\n",
                "\n",
                "print('\\nðŸŸ  URGENT ACTIONS (Next 24 hours):')\n",
                "if high_ips:\n",
                "    print(f'   1. Implement rate limiting for {len(high_ips)} HIGH-risk IPs')\n",
                "    print(f'   2. Review attack patterns and update WAF rules')\n",
                "    print(f'   3. Check for successful exploitation attempts')\n",
                "else:\n",
                "    print('   âœ“ No high-risk threats requiring urgent action')\n",
                "\n",
                "print('\\nðŸŸ¡ MEDIUM-TERM ACTIONS (This week):')\n",
                "print(f'   1. Patch {threat_summary[\"sql_injection_attempts\"]} SQL injection vulnerable endpoints')\n",
                "print(f'   2. Implement input validation for {threat_summary[\"xss_attempts\"]} XSS-vulnerable pages')\n",
                "print(f'   3. Review file access controls ({threat_summary[\"path_traversal_attempts\"]} path traversal attempts)')\n",
                "print(f'   4. Deploy WAF with updated threat signatures')\n",
                "\n",
                "print('\\nðŸ”µ STRATEGIC ACTIONS (This month):')\n",
                "print('   1. Implement real-time ML-based threat detection')\n",
                "print('   2. Set up automated blocking for ML-confirmed anomalies')\n",
                "print('   3. Integrate with threat intelligence feeds')\n",
                "print('   4. Conduct security training for dev team')\n",
                "print('   5. Schedule penetration testing')\n",
                "\n",
                "print('\\n' + '='*80)"
            ],
            "metadata": {},
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Export Security Intelligence Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "# Export all security intelligence data\n",
                "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "\n",
                "# 1. Risk assessment matrix\n",
                "risk_df.to_csv(f'../data/processed/security_risk_matrix_{timestamp}.csv', index=False)\n",
                "print(f'âœ“ Exported: security_risk_matrix_{timestamp}.csv')\n",
                "\n",
                "# 2. Threat actor profiles\n",
                "threat_actors.to_csv(f'../data/processed/threat_actor_profiles_{timestamp}.csv')\n",
                "print(f'âœ“ Exported: threat_actor_profiles_{timestamp}.csv')\n",
                "\n",
                "# 3. ML anomaly detection results\n",
                "ml_anomalies.to_csv(f'../data/processed/ml_anomalies_{timestamp}.csv')\n",
                "print(f'âœ“ Exported: ml_anomalies_{timestamp}.csv')\n",
                "\n",
                "# 4. Classified access log with all threat flags\n",
                "access_df.to_csv(f'../data/processed/classified_access_log_{timestamp}.csv', index=False)\n",
                "print(f'âœ“ Exported: classified_access_log_{timestamp}.csv')\n",
                "\n",
                "# 5. Executive summary report\n",
                "with open(f'../data/processed/security_executive_summary_{timestamp}.txt', 'w') as f:\n",
                "    f.write('='*80 + '\\n')\n",
                "    f.write('SECURITY ANALYSIS - EXECUTIVE SUMMARY\\n')\n",
                "    f.write('='*80 + '\\n\\n')\n",
                "    f.write(f'Analysis Date: {analysis_time}\\n')\n",
                "    f.write(f'Total Requests: {len(access_df):,}\\n')\n",
                "    f.write(f'Threats Detected: {threat_summary[\"total_threats\"]:,} ({threat_summary[\"threat_percentage\"]:.2f}%)\\n')\n",
                "    f.write(f'ML Anomalies: {len(ml_anomalies):,}\\n\\n')\n",
                "    f.write('CRITICAL FINDINGS:\\n')\n",
                "    f.write(f'- {len(critical_ips)} IPs require immediate blocking\\n')\n",
                "    f.write(f'- {len(high_ips)} IPs require urgent rate limiting\\n')\n",
                "    f.write(f'- {threat_summary[\"sql_injection_attempts\"]} SQL injection attempts\\n')\n",
                "    f.write(f'- {threat_summary[\"xss_attempts\"]} XSS attacks\\n')\n",
                "    f.write(f'- {threat_summary[\"path_traversal_attempts\"]} path traversal attempts\\n')\n",
                "\n",
                "print(f'âœ“ Exported: security_executive_summary_{timestamp}.txt')\n",
                "\n",
                "print('\\n' + '='*80)\n",
                "print('âœ… SECURITY ANALYSIS COMPLETE')\n",
                "print('='*80)\n",
                "print(f'All intelligence data exported to: data/processed/')\n",
                "print(f'Analysis timestamp: {timestamp}')\n",
                "print('\\nðŸ”’ Report Classification: INTERNAL USE ONLY')\n",
                "print('ðŸ“§ Distribute to: Security Core Team, SOC, CISO')\n",
                "print('='*80)"
            ],
            "metadata": {},
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
        "language_info": {"name": "python", "version": "3.8.0"}
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

with open('notebooks/SECURITY_TEAM_ML_Analysis.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=2)

print("âœ“ Security Core Team notebook created!")
